{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Cloning a Content Creator's Style from Instagram Content"
      ],
      "metadata": {
        "id": "DBtt_tm6-GhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Basic Setup for Instagram Content Scraping"
      ],
      "metadata": {
        "id": "pGG0qxte-RAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install instaloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Wnc3KaD9vprs",
        "outputId": "1a4ae6f5-61a0-49b0-afc7-5a3ae5192d13"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting instaloader\n",
            "  Downloading instaloader-4.14.tar.gz (65 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m61.4/65.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.10/dist-packages (from instaloader) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->instaloader) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->instaloader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->instaloader) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25->instaloader) (2024.8.30)\n",
            "Building wheels for collected packages: instaloader\n",
            "  Building wheel for instaloader (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for instaloader: filename=instaloader-4.14-py3-none-any.whl size=67805 sha256=eae33fce70d35c2afbf1e9c05edaba4ca9da23f20e977ee9d11691beb5f113c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c4/a8/eff3f91c3ba97d9a2b9a163e395cee000a99bc99557863db57\n",
            "Successfully built instaloader\n",
            "Installing collected packages: instaloader\n",
            "Successfully installed instaloader-4.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncb6GnLfvm3W"
      },
      "outputs": [],
      "source": [
        "# Install Instaloader: pip install instaloader\n",
        "\n",
        "\n",
        "import instaloader\n",
        "\n",
        "# Initialize Instaloader\n",
        "L = instaloader.Instaloader()\n",
        "\n",
        "# Login with Instagram credentials\n",
        "username = 'your_instagram_username'\n",
        "password = 'your_instagram_password'\n",
        "\n",
        "try:\n",
        "    L.login(username, password)\n",
        "    print(\"Logged in successfully.\")\n",
        "except instaloader.exceptions.BadCredentialsException:\n",
        "    print(\"Invalid credentials. Please check your username and password.\")\n",
        "\n",
        "# Now, load the profile\n",
        "profile_name = 'creative_logo_designers_'\n",
        "profile = instaloader.Profile.from_username(L.context, profile_name)\n",
        "\n",
        "# Extract captions\n",
        "captions = []\n",
        "for post in profile.get_posts():\n",
        "    captions.append(post.caption)\n",
        "\n",
        "print(captions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Style Analysis with Hugging Face Transformers"
      ],
      "metadata": {
        "id": "CztzPhJr-VbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "\n",
        "# Load a pre-trained model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Prepare captions for fine-tuning\n",
        "# Tokenize the data here\n",
        "train_encodings = tokenizer(captions, truncation=True, padding=True)\n",
        "\n",
        "# Training setup\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=1,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# Initialize Trainer and train model on captions\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_encodings,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "3gszFOhFwTG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Generating Personalized Product Reviews from E-commerce URLs"
      ],
      "metadata": {
        "id": "8v-RN8Fc-gpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "def scrape_product(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Example extraction\n",
        "    product_name = soup.find('h1').text if soup.find('h1') else \"Product\"\n",
        "    product_description = soup.find('p').text if soup.find('p') else \"No description available.\"\n",
        "\n",
        "    return product_name, product_description\n",
        "\n",
        "# Example product review generation\n",
        "def generate_review(product_name, product_description):\n",
        "    prompt = f\"Write a personalized review for a product named {product_name}. Description: {product_description}\"\n",
        "\n",
        "    # Assuming using GPT model for review generation\n",
        "    response = model(prompt)\n",
        "    return response[\"choices\"][0][\"text\"]\n",
        "\n",
        "url = \"https://www.example.com/product-page\"\n",
        "product_name, product_description = scrape_product(url)\n",
        "review = generate_review(product_name, product_description)\n",
        "print(review)\n"
      ],
      "metadata": {
        "id": "5XCqJZHh-jLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Creating Video Scripts in the Content Creator's Style"
      ],
      "metadata": {
        "id": "GSYAvIwS-mbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_script(topic):\n",
        "    prompt = f\"Write a script about {topic} in the style of {username}.\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs.input_ids, max_length=150, temperature=0.7, num_return_sequences=1)\n",
        "\n",
        "    script = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return script\n",
        "\n",
        "topic = \"reviewing the latest tech gadget\"\n",
        "print(generate_script(topic))\n"
      ],
      "metadata": {
        "id": "uGqqj2Fb-ou3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Voice Synthesis in the Creator’s Voice"
      ],
      "metadata": {
        "id": "RVmxDGVT-uKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "text = \"This is a sample video script generated by the AI content creator system.\"\n",
        "tts = gTTS(text=text, lang='en')\n",
        "tts.save(\"script_audio.mp3\")\n"
      ],
      "metadata": {
        "id": "jlw0BRjU-uwu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}